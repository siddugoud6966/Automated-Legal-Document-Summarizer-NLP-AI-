{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz7CRSup6L6VdZRRwLtmLb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddugoud6966/Automated-Legal-Document-Summarizer-NLP-AI-/blob/main/Automated_Legal_Document_Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3AMgg2Whqzz",
        "outputId": "e2796dcc-da01-4237-fcab-36b2787ae91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n",
            "E: Package 'libfluidsynth1' has no installation candidate\n",
            "Requirement already satisfied: libarchive in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from libarchive) (1.3.7)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot) (3.2.3)\n",
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.11/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.1.1)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.26.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install matplotlib-venn\n",
        "!apt-get -qq install -y libfluidsynth1\n",
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive\n",
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot\n",
        "!pip install cartopy\n",
        "import cartopy\n",
        "!pip install pymupdf\n",
        "import fitz\n",
        "\n",
        "import os\n",
        "import csv\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForTokenClassification\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Summarization pipeline setup\n",
        "model_name = \"shresthasingh/my_awesome_billsum_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# NER pipeline setup\n",
        "ner_tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        page_text = page.get_text()\n",
        "        text += page_text\n",
        "    return text\n",
        "\n",
        "def summarize_text(text, min_length=30):\n",
        "    return summarizer(text, min_length=min_length, do_sample=False)[0]['summary_text']\n",
        "\n",
        "def chunk_text(text, chunk_size=512):\n",
        "    words = text.split()\n",
        "    chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "def recursive_summarize(text, chunk_size=300, min_length=30):\n",
        "    if len(text.split()) <= chunk_size:\n",
        "        return summarize_text(text, min_length)\n",
        "\n",
        "    chunks = chunk_text(text, chunk_size)\n",
        "    summaries = [summarize_text(chunk, min_length) for chunk in chunks]\n",
        "    combined_summary = ' '.join(summaries)\n",
        "    return recursive_summarize(combined_summary, chunk_size, min_length)\n",
        "\n",
        "def extract_named_entities(text, chunk_size=256):\n",
        "    chunks = chunk_text(text, chunk_size)\n",
        "    entities = {'PER': set(), 'ORG': set(), 'LOC': set()}\n",
        "\n",
        "    for chunk in chunks:\n",
        "        ner_results = ner_pipeline(chunk)\n",
        "        for result in ner_results:\n",
        "            entity_type = result['entity'].split('-')[-1]\n",
        "            if entity_type in entities:\n",
        "                entity_value = result['word'].replace('##', '')\n",
        "                entities[entity_type].add(entity_value)\n",
        "\n",
        "    return entities\n",
        "\n",
        "def process_legal_document(pdf_path):\n",
        "    # Extract text from PDF\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Generate summary\n",
        "    summary = recursive_summarize(text)\n",
        "\n",
        "    # Extract named entities\n",
        "    entities = extract_named_entities(text)\n",
        "\n",
        "    return summary, entities\n",
        "\n",
        "def process_directory(directory_path):\n",
        "    output_data = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(directory_path, filename)\n",
        "            summary, entities = process_legal_document(pdf_path)\n",
        "            persons = ', '.join(entities['PER'])\n",
        "            organizations = ', '.join(entities['ORG'])\n",
        "            locations = ', '.join(entities['LOC'])\n",
        "            output_data.append([filename, summary, persons, organizations, locations])\n",
        "\n",
        "    output_csv = os.path.join(directory_path, \"legal_document_analysis.csv\")\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"File name\", \"File Summary\", \"Persons of Interest\", \"Organizations of Interest\", \"Locations of Interest\"])\n",
        "        for data in output_data:\n",
        "            writer.writerow(data)\n",
        "\n",
        "    print(f\"\\nAnalysis results have been saved to: {os.path.abspath(output_csv)}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    directory_path = input(\"Enter the path to the directory containing legal PDF files: \")\n",
        "    process_directory(directory_path)"
      ]
    }
  ]
}